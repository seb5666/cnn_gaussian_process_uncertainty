{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = np.load('data/mnist_train.npy')\n",
    "X_train = np.load('data/X_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "mnist_test = np.load('data/mnist_test.npy')\n",
    "X_test = np.load('data/X_test.npy')\n",
    "y_test = np.load('data/y_test.npy')\n",
    "\n",
    "test_p, test_var = np.load(\"predictions/X_test.npy\")\n",
    "train_p, train_var = np.load(\"predictions/X_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(test_p.shape)\n",
    "print(test_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missclassifications: 72\n",
      "Accuracy: 99.28\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(test_p, axis=-1)\n",
    "correct_imgs = np.argwhere(predictions == y_test)\n",
    "incorrect_imgs = np.argwhere(predictions != y_test)\n",
    "print(\"Number of missclassifications: {}\".format(len(incorrect_imgs)))\n",
    "print(\"Accuracy: {}\".format(len(correct_imgs)/len(predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9729\n",
      "0.979955680902498\n",
      "14\n",
      "0.19444444444444445\n"
     ]
    }
   ],
   "source": [
    "top_vars = test_var[np.arange(len(test_var)), predictions]\n",
    "correct_vars = top_vars[correct_imgs]\n",
    "incorrect_vars = top_vars[incorrect_imgs]\n",
    "correct_stds = np.sqrt(correct_vars)\n",
    "incorrect_stds = np.sqrt(incorrect_vars)\n",
    "\n",
    "print(len(correct_stds[correct_stds < 0.1]))\n",
    "print(len(correct_stds[correct_stds < 0.1])/len(correct_stds))\n",
    "\n",
    "print(len(incorrect_stds[incorrect_stds < 0.1]))\n",
    "print(len(incorrect_stds[incorrect_stds < 0.1])/len(incorrect_stds))\n",
    "\n",
    "plt.hist(correct_stds, bins=100)\n",
    "plt.figure()\n",
    "plt.xlim([0, 0.1])\n",
    "plt.hist(correct_stds[correct_stds < 0.1], bins=100)\n",
    "plt.figure()\n",
    "plt.hist(incorrect_stds, bins=100, cumulative=False, normed=True);\n",
    "\n",
    "#TODO draw cummulative top stds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499996610361\n",
      "0.498708894874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12eb62470>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cum_dense_std(xs, stds):\n",
    "    def y(x):\n",
    "        return len(stds[stds < x])/len(stds)\n",
    "    \n",
    "    return np.array([y(x) for x in xs])\n",
    "\n",
    "print(correct_stds.max())\n",
    "print(incorrect_stds.max())\n",
    "xs = np.linspace(0,0.55, num=1000)\n",
    "# plt.title(\"Cumulative distribution of standard deviations\")\n",
    "plt.figure()\n",
    "plt.plot(xs, cum_dense_std(xs, correct_stds), label=\"Correctly classified images\")\n",
    "plt.plot(xs, cum_dense_std(xs, incorrect_stds), label=\"Incorreclty classified images\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Standard deviation of for the class with highest probability\")\n",
    "plt.ylabel(\"Cumulative frequency\")\n",
    "plt.savefig(\"figs/mnist_cum_stds.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "582\n",
      "8\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 10 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "index = incorrect_imgs[4][0]\n",
    "print(index)\n",
    "print(y_test[index])\n",
    "print(predictions[index])\n",
    "#Plot uncertainty distributions\n",
    "plt.bar(np.arange(10), test_p[index].squeeze(), yerr=test_var[index].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_image(axes, index):\n",
    "    ax.imshow(mnist_test[index].reshape(28,28), cmap=plt.cm.gray_r) \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig = plt.figure()\n",
    "h = 9\n",
    "w = 8\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        k = i * w + j\n",
    "        index = incorrect_imgs[k][0]\n",
    "        ax = fig.add_subplot(h, w, k+1)\n",
    "        draw_image(ax, index)\n",
    "# fig.savefig(\"figs/incorrect_mnist\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_y', '__globals__', '__version__', 'train_y', 'train_x', 'test_x', '__header__']\n",
      "['test_y', '__globals__', '__version__', 'train_y', 'train_x', 'test_x', '__header__']\n",
      "['test_y', '__globals__', '__version__', 'train_y', 'train_x', 'test_x', '__header__']\n"
     ]
    }
   ],
   "source": [
    "def load_data(DATA_DIR):\n",
    "    rows, cols = 28, 28\n",
    "    nb_classes = 10\n",
    "\n",
    "    mat = scipy.io.loadmat(DATA_DIR)\n",
    "    print(list(mat.keys()))\n",
    "    X_train = mat['train_x']\n",
    "    Y_train = np.argmax(mat['train_y'], axis=-1)\n",
    "    X_test = mat['test_x']\n",
    "    Y_test = np.argmax(mat['test_y'], axis=-1)\n",
    "    \n",
    "    # Reshape and format input\n",
    "    \n",
    "    #Renormalize images\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_train /= 255.0\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_test /= 255.0\n",
    "\n",
    "    return (X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_y', '__globals__', '__version__', 'train_y', 'train_x', 'test_x', '__header__']\n",
      "0.9334\n"
     ]
    }
   ],
   "source": [
    "(noisy_nmist_X_train, noisy_nmist_Y_train, noisy_nmist_X_test, noisy_nmist_Y_test) = load_data('data/mnist-with-awgn.mat')\n",
    "\n",
    "noisy_p, noisy_var = np.load(\"predictions/noisy_test.npy\")\n",
    "noisy_predictions = np.argmax(noisy_p, axis=-1)\n",
    "noisy_correct_imgs = np.argwhere(noisy_predictions == noisy_nmist_Y_test)\n",
    "noisy_incorrect_imgs = np.argwhere(noisy_predictions != noisy_nmist_Y_test)\n",
    "noisy_top_stds = np.sqrt(noisy_var[np.arange(len(noisy_var)), noisy_predictions])\n",
    "noisy_correct_stds, noisy_incorrect_stds = noisy_top_stds[noisy_correct_imgs], noisy_top_stds[noisy_incorrect_imgs]\n",
    "print(len(noisy_correct_imgs)/len(noisy_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_y', '__globals__', '__version__', 'train_y', 'train_x', 'test_x', '__header__']\n",
      "0.9209\n"
     ]
    }
   ],
   "source": [
    "(blur_nmist_X_train, blur_nmist_Y_train, blur_nmist_X_test, blur_nmist_y_test) = load_data('data/mnist-with-motion-blur.mat')\n",
    "\n",
    "blur_p, blur_var = np.load(\"predictions/blur_test.npy\")\n",
    "blur_predictions = np.argmax(blur_p, axis=-1)\n",
    "blur_correct_imgs = np.argwhere(blur_predictions == blur_nmist_y_test)\n",
    "blur_incorrect_imgs = np.argwhere(blur_predictions != blur_nmist_y_test)\n",
    "blur_top_stds = np.sqrt(blur_var[np.arange(len(blur_var)), blur_predictions])\n",
    "blur_correct_stds, blur_incorrect_stds = blur_top_stds[blur_correct_imgs], blur_top_stds[blur_incorrect_imgs]\n",
    "print(len(blur_correct_imgs)/len(blur_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_y', '__globals__', '__version__', 'train_y', 'train_x', 'test_x', '__header__']\n",
      "0.7013\n"
     ]
    }
   ],
   "source": [
    "(contrast_nmist_X_train, contrast_nmist_y_train, contrast_nmist_X_test, contrast_nmist_y_test) = load_data('data/mnist-with-reduced-contrast-and-awgn.mat')\n",
    "\n",
    "contrast_p, contrast_var = np.load(\"predictions/contrast_test.npy\")\n",
    "contrast_predictions = np.argmax(contrast_p, axis=-1)\n",
    "contrast_correct_imgs = np.argwhere(contrast_predictions == contrast_nmist_y_test)\n",
    "contrast_incorrect_imgs = np.argwhere(contrast_predictions != contrast_nmist_y_test)\n",
    "contrast_top_stds = np.sqrt(contrast_var[np.arange(len(contrast_var)), contrast_predictions])\n",
    "contrast_correct_stds, contrast_incorrect_stds = contrast_top_stds[contrast_correct_imgs], contrast_top_stds[contrast_incorrect_imgs]\n",
    "print(len(contrast_correct_imgs)/len(contrast_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9334\n",
      "666\n",
      "9209\n",
      "791\n",
      "7013\n",
      "2987\n"
     ]
    }
   ],
   "source": [
    "def plot_cum_dense_std(ax, correct_stds, incorrect_stds, title=\"\"):\n",
    "    def cum_dense_std(xs, stds):\n",
    "        def y(x):\n",
    "            return len(stds[stds < x])/len(stds)\n",
    "\n",
    "        return np.array([y(x) for x in xs])\n",
    "\n",
    "    print(len(correct_stds))\n",
    "    print(len(incorrect_stds))\n",
    "    \n",
    "    xs = np.linspace(0,0.55, num=1000)\n",
    "    # plt.title(\"Cumulative distribution of standard deviations\")\n",
    "    ax.plot(xs, cum_dense_std(xs, correct_stds), label=\"Correctly classified\")\n",
    "    ax.plot(xs, cum_dense_std(xs, incorrect_stds), label=\"Incorreclty classified\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set_xlabel(\"Standard deviation\")\n",
    "    ax.set_ylabel(\"Cumulative frequency\")\n",
    "    ax.set_title(title)\n",
    "    # plt.savefig(\"figs/mnist_cum_stds.png\", bbox_inches=\"tight\")\n",
    "  \n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "plot_cum_dense_std(ax1, noisy_correct_stds, noisy_incorrect_stds, title=\"Additive white Gaussian noise\")\n",
    "plot_cum_dense_std(ax2, blur_correct_stds, blur_incorrect_stds, title=\"Motion blur\")\n",
    "plot_cum_dense_std(ax3, contrast_correct_stds, contrast_incorrect_stds, title=\"Reduced contrast and AWGN\")\n",
    "plt.savefig(\"figs/noisy_mnist_cum_stds.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 646.,    3.,    2.,    3.,    2.,    2.,    2.,    2.,    1.,    3.]),\n",
       " array([ 0.04353201,  0.08037963,  0.11722726,  0.15407489,  0.19092251,\n",
       "         0.22777014,  0.26461777,  0.3014654 ,  0.33831302,  0.37516065,\n",
       "         0.41200828]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(noisy_correct_stds)\n",
    "plt.figure()\n",
    "plt.hist(noisy_incorrect_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlbook]",
   "language": "python",
   "name": "conda-env-mlbook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
